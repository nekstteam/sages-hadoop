
WordCount

1. Wrzucamy nasze dane na hdfs'a

hdfs dfs -copyFromLocal /home/sages/Sages/dane/lektury /user/sages/
hdfs dfs -copyFromLocal /home/sages/Sages/dane/lektury-100/ /user/sages/
hdfs dfs -copyFromLocal /home/sages/Sages/dane/lektury-one-file/ /user/sages/

2. Uruchomienie projektu
#hadoop jar /home/sages/Sages/sages-hadoop/mapreduce/target/mapreduce-1.0-SNAPSHOT-jar-with-dependencies.jar /user/sages/lektury /user/sages/lektury-output
hadoop jar /home/sages/Sages/sages-hadoop/mapreduce/target/mapreduce-1.0-SNAPSHOT-jar-with-dependencies.jar /user/sages/lektury-100 /user/sages/lektury-100-output
hadoop jar /home/sages/Sages/sages-hadoop/mapreduce/target/mapreduce-1.0-SNAPSHOT-jar-with-dependencies.jar /user/sages/lektury-one-file /user/sages/lektury-one-file-output

3 Jesli chcemy usunąć to co wcześniej wrzuciliśmy (dane plus wyniki)

hdfs dfs -rm -f -r -skipTrash /user/sages/lektury
hdfs dfs -rm -f -r -skipTrash /user/sages/lektury-100
hdfs dfs -rm -f -r -skipTrash /user/sages/lektury-one-file

hdfs dfs -rm -f -r -skipTrash /user/sages/lektury-output
hdfs dfs -rm -f -r -skipTrash /user/sages/lektury-100-output
hdfs dfs -rm -f -r -skipTrash /user/sages/lektury-one-file-output